{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape:(1279, 12)\n",
      "Test dataset shape:(320, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.547170</td>\n",
       "      <td>0.436709</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.140753</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.280277</td>\n",
       "      <td>0.996523</td>\n",
       "      <td>0.867830</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.778523</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0.383648</td>\n",
       "      <td>0.132911</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.090323</td>\n",
       "      <td>0.108020</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.570934</td>\n",
       "      <td>0.987556</td>\n",
       "      <td>0.810474</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.798658</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0.685535</td>\n",
       "      <td>0.246835</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.116129</td>\n",
       "      <td>0.193126</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.048443</td>\n",
       "      <td>0.994530</td>\n",
       "      <td>0.822943</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.657718</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>0.553459</td>\n",
       "      <td>0.433544</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.103226</td>\n",
       "      <td>0.144026</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.079585</td>\n",
       "      <td>0.993275</td>\n",
       "      <td>0.827930</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.630872</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.655063</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.119476</td>\n",
       "      <td>0.152778</td>\n",
       "      <td>0.186851</td>\n",
       "      <td>0.995327</td>\n",
       "      <td>0.840399</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.664430</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "493       0.547170          0.436709         0.31        0.193548   0.140753   \n",
       "354       0.383648          0.132911         0.40        0.090323   0.108020   \n",
       "342       0.685535          0.246835         0.47        0.116129   0.193126   \n",
       "834       0.553459          0.433544         0.26        0.103226   0.144026   \n",
       "705       0.528302          0.655063         0.15        0.387097   0.119476   \n",
       "\n",
       "     free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
       "493             0.319444              0.280277  0.996523  0.867830      0.370   \n",
       "354             0.562500              0.570934  0.987556  0.810474      0.295   \n",
       "342             0.083333              0.048443  0.994530  0.822943      0.375   \n",
       "834             0.222222              0.079585  0.993275  0.827930      0.235   \n",
       "705             0.152778              0.186851  0.995327  0.840399      0.245   \n",
       "\n",
       "      alcohol  quality  \n",
       "493  0.778523    0.750  \n",
       "354  0.798658    0.750  \n",
       "342  0.657718    0.750  \n",
       "834  0.630872    0.625  \n",
       "705  0.664430    0.625  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv('wine_red.csv',sep = ';')# Get data\n",
    "\n",
    "# copy the data and normalize\n",
    "df_scaled = data.copy()\n",
    "for column in df_scaled.columns:\n",
    "    df_scaled[column] = df_scaled[column]  / df_scaled[column].abs().max()\n",
    "\n",
    "df_scaled_shape = df_scaled.shape\n",
    "df_scaled.head()\n",
    "\n",
    "# split the data into train and test set\n",
    "train, test = train_test_split(df_scaled, test_size=0.2, random_state=42, shuffle=True)\n",
    "print('Train dataset shape:'+str(train.shape))\n",
    "print('Test dataset shape:'+str(test.shape))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "#Define model hyperparameters\n",
    "batch_size = 100\n",
    "x_dim  = train.shape[1]\n",
    "hidden_dim = 10\n",
    "latent_dim = 6\n",
    "lr = 1e-3\n",
    "epochs = 50\n",
    "\n",
    "\n",
    "# Define custom test Train and test datasets\n",
    "class train_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, train):\n",
    "        # data loading\n",
    "        state1 = np.float32(train)\n",
    "        self.st1 = torch.from_numpy(state1)\n",
    "        self.n_samples1 = state1.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.st1[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples1\n",
    "\n",
    "\n",
    "class test_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, test):\n",
    "        # data loading\n",
    "        state2 = np.float32(test)\n",
    "        self.st2 = torch.from_numpy(state2)\n",
    "        self.n_samples2 = state2.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.st2[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples2\n",
    "\n",
    "\n",
    "# Dataloader loads data for training\n",
    "train_loader = DataLoader(dataset = train_dataset(train),batch_size = 100, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_dataset(test),batch_size = 100, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Encoder architecture\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.FC1     = nn.Linear(input_dim, hidden_dim)\n",
    "        self.FC2     = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.FC_mu   = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.FC_var  = nn.Linear (hidden_dim, latent_dim)\n",
    "\n",
    "        self.training = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_       = F.relu(self.FC1(x))\n",
    "        h_       = F.relu(self.FC2(h_))\n",
    "        mean     = self.FC_mu(h_) # mu of simple tractable distribution  Q\n",
    "        log_var  = self.FC_var(h_)  # sigma of Q\n",
    "\n",
    "        return mean, log_var\n",
    "# Define Decoder architecture\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.FC1    = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.FC2    = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.FC_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h     = F.relu(self.FC1(x))\n",
    "        h     = F.relu(self.FC2(h))\n",
    "\n",
    "        #x_hat = torch.sigmoid(self.FC_output(h))\n",
    "        x_hat = self.FC_out(h)\n",
    "        return x_hat\n",
    "\n",
    "# Define the complete model\n",
    "encoder = Encoder(input_dim= x_dim, hidden_dim= hidden_dim, latent_dim= latent_dim)\n",
    "decoder = Decoder(latent_dim= latent_dim, hidden_dim = hidden_dim, output_dim = x_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, Encoder=encoder, Decoder=decoder):\n",
    "        super(Model, self).__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "\n",
    "    def reparam(self, mean, var):\n",
    "        epsilon = torch.randn_like(var)# sampling epsilon\n",
    "        z       = mean + var*epsilon # reparameterization trick\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, log_var    = self.Encoder(x)\n",
    "        z                = self.reparam(mean, torch.exp(0.5 * log_var)) # takes exponential function (log var -> var)\n",
    "        x_hat            = self.Decoder(z)\n",
    "\n",
    "        return x_hat, mean, log_var\n",
    "\n",
    "\n",
    "#model = Model(Encoder=encoder, Decoder=decoder)\n",
    "model = Model()\n",
    "\n",
    "# Define Loss function and optimizer\n",
    "\n",
    "from torch.optim import Adam\n",
    "loss_fun = torch.nn.MSELoss()\n",
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    reproduction_loss = loss_fun(x_hat, x)\n",
    "    KLDiv             = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "    return reproduction_loss + KLDiv\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating training process....\n",
      "\tEpoch 1 \tAverage Loss:  0.19118167479832968\n",
      "\tEpoch 2 \tAverage Loss:  0.1415359115600586\n",
      "\tEpoch 3 \tAverage Loss:  0.10914118687311808\n",
      "\tEpoch 4 \tAverage Loss:  0.0857047414779663\n",
      "\tEpoch 5 \tAverage Loss:  0.06701654394467672\n",
      "\tEpoch 6 \tAverage Loss:  0.05115667243798574\n",
      "\tEpoch 7 \tAverage Loss:  0.03364133695761363\n",
      "\tEpoch 8 \tAverage Loss:  0.018227195491393407\n",
      "\tEpoch 9 \tAverage Loss:  0.009336739579836528\n",
      "\tEpoch 10 \tAverage Loss:  0.004675226807594299\n",
      "\tEpoch 11 \tAverage Loss:  0.0023275419200460114\n",
      "\tEpoch 12 \tAverage Loss:  0.0012140460746983687\n",
      "\tEpoch 13 \tAverage Loss:  0.0007199443317949772\n",
      "\tEpoch 14 \tAverage Loss:  0.0005258076389630635\n",
      "\tEpoch 15 \tAverage Loss:  0.000457272840042909\n",
      "\tEpoch 16 \tAverage Loss:  0.0004224411149819692\n",
      "\tEpoch 17 \tAverage Loss:  0.0003985140938311815\n",
      "\tEpoch 18 \tAverage Loss:  0.0003872819772611062\n",
      "\tEpoch 19 \tAverage Loss:  0.00036963816887388627\n",
      "\tEpoch 20 \tAverage Loss:  0.0003515945561230183\n",
      "\tEpoch 21 \tAverage Loss:  0.000333395516499877\n",
      "\tEpoch 22 \tAverage Loss:  0.0003088273604710897\n",
      "\tEpoch 23 \tAverage Loss:  0.00029051853188623983\n",
      "\tEpoch 24 \tAverage Loss:  0.0002792672285189231\n",
      "\tEpoch 25 \tAverage Loss:  0.00026501688174903395\n",
      "\tEpoch 26 \tAverage Loss:  0.00025931962300091983\n",
      "\tEpoch 27 \tAverage Loss:  0.00024846223803857965\n",
      "\tEpoch 28 \tAverage Loss:  0.00024209974023203055\n",
      "\tEpoch 29 \tAverage Loss:  0.00023702182962248724\n",
      "\tEpoch 30 \tAverage Loss:  0.0002296899352222681\n",
      "\tEpoch 31 \tAverage Loss:  0.00022379353952904543\n",
      "\tEpoch 32 \tAverage Loss:  0.00021861125715076922\n",
      "\tEpoch 33 \tAverage Loss:  0.00021404158013562361\n",
      "\tEpoch 34 \tAverage Loss:  0.00020938174333423376\n",
      "\tEpoch 35 \tAverage Loss:  0.00020596085659538706\n",
      "\tEpoch 36 \tAverage Loss:  0.00020152731177707514\n",
      "\tEpoch 37 \tAverage Loss:  0.00020025020620475213\n",
      "\tEpoch 38 \tAverage Loss:  0.0001967377479498585\n",
      "\tEpoch 39 \tAverage Loss:  0.0001952558297974368\n",
      "\tEpoch 40 \tAverage Loss:  0.00019195420822749534\n",
      "\tEpoch 41 \tAverage Loss:  0.00019030690736447772\n",
      "\tEpoch 42 \tAverage Loss:  0.00018759471752370397\n",
      "\tEpoch 43 \tAverage Loss:  0.0001840834692120552\n",
      "\tEpoch 44 \tAverage Loss:  0.00018170452676713467\n",
      "\tEpoch 45 \tAverage Loss:  0.00017925121278191606\n",
      "\tEpoch 46 \tAverage Loss:  0.00017771271523088218\n",
      "\tEpoch 47 \tAverage Loss:  0.00017834966924662392\n",
      "\tEpoch 48 \tAverage Loss:  0.00017544840152064958\n",
      "\tEpoch 49 \tAverage Loss:  0.00017527016811072827\n",
      "\tEpoch 50 \tAverage Loss:  0.0001720299486381312\n"
     ]
    }
   ],
   "source": [
    "# Type01-Training pipeline\n",
    "\n",
    "print(\"Initiating training process....\")\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    overall_loss = 0\n",
    "    for batch_idx, (x) in enumerate(train_loader):\n",
    "        #x = x.view(batch_size, x_dim)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_hat, mean, log_var = model(x)\n",
    "        loss = loss_function(x, x_hat, mean, log_var)\n",
    "\n",
    "        overall_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"\\tEpoch\", epoch + 1, \"\\tAverage Loss: \", overall_loss / (batch_idx*batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training VAE...\n",
      "\tEpoch 1 complete! \tAverage Loss:  0.14018994967142742\n",
      "\tEpoch 2 complete! \tAverage Loss:  0.105631023645401\n",
      "\tEpoch 3 complete! \tAverage Loss:  0.085298144419988\n",
      "\tEpoch 4 complete! \tAverage Loss:  0.06864291548728943\n",
      "\tEpoch 5 complete! \tAverage Loss:  0.04797291874885559\n",
      "\tEpoch 6 complete! \tAverage Loss:  0.027941418488820393\n",
      "\tEpoch 7 complete! \tAverage Loss:  0.015323872715234756\n",
      "\tEpoch 8 complete! \tAverage Loss:  0.008733616272608439\n",
      "\tEpoch 9 complete! \tAverage Loss:  0.005061315720280011\n",
      "\tEpoch 10 complete! \tAverage Loss:  0.002969293147325516\n",
      "\tEpoch 11 complete! \tAverage Loss:  0.001787432295580705\n",
      "\tEpoch 12 complete! \tAverage Loss:  0.00115418566390872\n",
      "\tEpoch 13 complete! \tAverage Loss:  0.0008669235308965047\n",
      "\tEpoch 14 complete! \tAverage Loss:  0.0007376163049290578\n",
      "\tEpoch 15 complete! \tAverage Loss:  0.0006664695280293624\n",
      "\tEpoch 16 complete! \tAverage Loss:  0.0006180932900557916\n",
      "\tEpoch 17 complete! \tAverage Loss:  0.0005681644038607677\n",
      "\tEpoch 18 complete! \tAverage Loss:  0.0005365141046543916\n",
      "\tEpoch 19 complete! \tAverage Loss:  0.000507304755349954\n",
      "\tEpoch 20 complete! \tAverage Loss:  0.0004827344262351592\n",
      "\tEpoch 21 complete! \tAverage Loss:  0.0004572565977772077\n",
      "\tEpoch 22 complete! \tAverage Loss:  0.00044079347513616086\n",
      "\tEpoch 23 complete! \tAverage Loss:  0.0004246556262175242\n",
      "\tEpoch 24 complete! \tAverage Loss:  0.00040345004138847194\n",
      "\tEpoch 25 complete! \tAverage Loss:  0.000388633506372571\n",
      "\tEpoch 26 complete! \tAverage Loss:  0.00037454529044528805\n",
      "\tEpoch 27 complete! \tAverage Loss:  0.00036449735052883624\n",
      "\tEpoch 28 complete! \tAverage Loss:  0.000350885729615887\n",
      "\tEpoch 29 complete! \tAverage Loss:  0.00034172405954450367\n",
      "\tEpoch 30 complete! \tAverage Loss:  0.0003300876558447878\n",
      "\tEpoch 31 complete! \tAverage Loss:  0.00032350806519389154\n",
      "\tEpoch 32 complete! \tAverage Loss:  0.0003133473622923096\n",
      "\tEpoch 33 complete! \tAverage Loss:  0.0003038338680441181\n",
      "\tEpoch 34 complete! \tAverage Loss:  0.00029723767035951215\n",
      "\tEpoch 35 complete! \tAverage Loss:  0.0002913311853383978\n",
      "\tEpoch 36 complete! \tAverage Loss:  0.000283228096862634\n",
      "\tEpoch 37 complete! \tAverage Loss:  0.0002772012089068691\n",
      "\tEpoch 38 complete! \tAverage Loss:  0.0002715114193658034\n",
      "\tEpoch 39 complete! \tAverage Loss:  0.00026529188733547926\n",
      "\tEpoch 40 complete! \tAverage Loss:  0.00026232906306783356\n",
      "\tEpoch 41 complete! \tAverage Loss:  0.0002574699760104219\n",
      "\tEpoch 42 complete! \tAverage Loss:  0.0002530164442335566\n",
      "\tEpoch 43 complete! \tAverage Loss:  0.0002488292846828699\n",
      "\tEpoch 44 complete! \tAverage Loss:  0.00024282082760085662\n",
      "\tEpoch 45 complete! \tAverage Loss:  0.00023906776526321966\n",
      "\tEpoch 46 complete! \tAverage Loss:  0.0002360536887620886\n",
      "\tEpoch 47 complete! \tAverage Loss:  0.00023246783142288525\n",
      "\tEpoch 48 complete! \tAverage Loss:  0.00022887644357979297\n",
      "\tEpoch 49 complete! \tAverage Loss:  0.00022695706070711215\n",
      "\tEpoch 50 complete! \tAverage Loss:  0.00022239210860182843\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Type2- Training with Testing pipeline\n",
    "# Alternative to above Cell\n",
    "\n",
    "print(\"Initiating training and testing process....\")\n",
    "\n",
    "def train(dataloader, model, loss_function, optimizer, batch_size, overall_train_loss, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (x) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_hat, mean, log_var = model(x)\n",
    "        loss = loss_function(x, x_hat, mean, log_var)\n",
    "\n",
    "        overall_train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"\\tEpoch\", epoch + 1, \"complete!\", \"\\tAverage Loss: \", overall_train_loss / (batch_idx*batch_size))\n",
    "    return overall_train_loss\n",
    "\n",
    "def test(dataloader, model, loss_function, overall_test_loss):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (y) in enumerate(dataloader):\n",
    "            x_hat, mean, log_var = model(y)\n",
    "            overall_test_loss += loss_function(y, x_hat, mean, log_var)\n",
    "    return overall_test_loss\n",
    "\n",
    "epochs = 50\n",
    "otrl = []\n",
    "otel = []\n",
    "for epoch in range(epochs):\n",
    "    overall_train_loss = 0\n",
    "    overall_test_loss = 0\n",
    "    otrl.append(train(train_loader, model, loss_function, optimizer, batch_size, overall_train_loss,epoch))\n",
    "    otel.append(test(test_loader, model, loss_function, overall_test_loss))\n",
    "\n",
    "xc = np.arange(len(otrl))\n",
    "plt.plot(xc, otrl, '-b', label = 'Overall Train loss')\n",
    "plt.plot(xc, otel, '-g', label = 'Overall Test loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
